{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# word2vec\n",
    "\n",
    "Ten notatnik ma na celu przedstawienie sposobu tworzenia i wykorzystania reprezentacji werktorowych na przykładzie algorytmu word2vec. W trakcie zadania najpierw stworzymy prostą reprezentację wektorową, a następnie spróbujemy wczytać gotowy model nauczony na dużym korpusie tekstowym.\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ wiedzieć na czym polega word2vec,\n",
    "+ potrafić stworzyć word2vec na własnych danych,\n",
    "+ potrafić wykorzystać word2vec do:\n",
    "\t+ znalezienia podobnych słów,\n",
    "\t+ wyszukiwania słów na zasadzie \"reguły trzech\", \n",
    "\t+ wykrywania niepasujących słów,\n",
    "\t+ do tworzenia wektora cech nadającego się do klasyfikacji,\n",
    "+ wczytać i wykorzystać gotowy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosty model\n",
    "\n",
    "Najpierw wczytamy odpowiednie biblioteki i stworzymy mały zbiór treningowy na podstawie znanej piosenki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, re, nltk\n",
    "import pandas as pd\n",
    "\n",
    "RE_SPACES = re.compile(\"\\s+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "song = \"\"\"Gdzie strumyk płynie z wolna,\n",
    "Rozsiewa zioła maj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Zielony gaj.\n",
    "\n",
    "W tym gaju tak ponuro,\n",
    "Że aż przeraża mnie,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "samotnej źle.\n",
    "\n",
    "Wtem harcerz idzie z wolna.\n",
    "„Stokrotko, witam cię,\n",
    "Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?”\n",
    "\"Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?\n",
    "Czy nie, czy nie?\n",
    "\n",
    "Stokrotka się zgodziła\n",
    "I poszli w ciemny las,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "w pokrzywy wlazł.\n",
    "\n",
    "A ona, ona, ona,\n",
    "Cóż biedna robić ma,\n",
    "Nad gapą pochylona\n",
    "I śmieje się: ha, ha,\n",
    "Nad gapą pochylona\n",
    "I śmieje: się ha, ha,\n",
    "ha, ha, ha, ha.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1: Podziel piosenkę na wersy, a wersy tokenizuj spacjami. W efekcie powinieneś stworzyć listę list i przypisać ją do zmiennej `sentences`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gdzie', 'strumyk', 'płynie', 'z', 'wolna,'], ['Rozsiewa', 'zioła', 'maj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Zielony', 'gaj.'], [''], ['W', 'tym', 'gaju', 'tak', 'ponuro,'], ['Że', 'aż', 'przeraża', 'mnie,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['samotnej', 'źle.'], [''], ['Wtem', 'harcerz', 'idzie', 'z', 'wolna.'], ['„Stokrotko,', 'witam', 'cię,'], ['Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?”'], ['\"Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?'], ['Czy', 'nie,', 'czy', 'nie?'], [''], ['Stokrotka', 'się', 'zgodziła'], ['I', 'poszli', 'w', 'ciemny', 'las,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['w', 'pokrzywy', 'wlazł.'], [''], ['A', 'ona,', 'ona,', 'ona,'], ['Cóż', 'biedna', 'robić', 'ma,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje', 'się:', 'ha,', 'ha,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje:', 'się', 'ha,', 'ha,'], ['ha,', 'ha,', 'ha,', 'ha.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = [re.split(RE_SPACES,verse) for verse in re.split(\"\\n\",song)]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając tekst podzielony na zdania a zdania na tokeny, możemy nauczyć model word2vec.\n",
    "\n",
    "**Zad. 2: Naucz model word2vec. [Sprawdź](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) za co odpowiedzialne są parametry `min_count` i `iter`. Jakie inne parametry mogą być przydatne?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:41,953 : INFO : collecting all words and their counts\n",
      "2021-01-21 23:39:41,953 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 23:39:41,954 : INFO : collected 80 word types from a corpus of 144 raw words and 39 sentences\n",
      "2021-01-21 23:39:41,954 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 23:39:41,955 : INFO : effective_min_count=1 retains 80 unique words (100% of original 80, drops 0)\n",
      "2021-01-21 23:39:41,956 : INFO : effective_min_count=1 leaves 144 word corpus (100% of original 144, drops 0)\n",
      "2021-01-21 23:39:41,957 : INFO : deleting the raw counts dictionary of 80 items\n",
      "2021-01-21 23:39:41,958 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2021-01-21 23:39:41,959 : INFO : downsampling leaves estimated 50 word corpus (35.2% of prior 144)\n",
      "2021-01-21 23:39:41,959 : INFO : estimated required memory for 80 words and 100 dimensions: 104000 bytes\n",
      "2021-01-21 23:39:41,960 : INFO : resetting layer weights\n",
      "2021-01-21 23:39:41,982 : INFO : training model with 3 workers on 80 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 23:39:41,985 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:41,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:41,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:41,986 : INFO : EPOCH - 1 : training on 144 raw words (48 effective words) took 0.0s, 20975 effective words/s\n",
      "2021-01-21 23:39:41,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:41,991 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:41,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:41,992 : INFO : EPOCH - 2 : training on 144 raw words (53 effective words) took 0.0s, 19134 effective words/s\n",
      "2021-01-21 23:39:41,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:41,996 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:41,997 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:41,998 : INFO : EPOCH - 3 : training on 144 raw words (47 effective words) took 0.0s, 17121 effective words/s\n",
      "2021-01-21 23:39:42,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,004 : INFO : EPOCH - 4 : training on 144 raw words (62 effective words) took 0.0s, 28238 effective words/s\n",
      "2021-01-21 23:39:42,007 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,007 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,008 : INFO : EPOCH - 5 : training on 144 raw words (51 effective words) took 0.0s, 33441 effective words/s\n",
      "2021-01-21 23:39:42,009 : INFO : training on a 720 raw words (261 effective words) took 0.0s, 9970 effective words/s\n",
      "2021-01-21 23:39:42,009 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-01-21 23:39:42,010 : INFO : precomputing L2-norms of word weight vectors\n",
      "2021-01-21 23:39:42,012 : WARNING : vectors for words {'las', 'gaj'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=80, size=100, alpha=0.025)\n",
      "<gensim.models.word2vec.Word2VecVocab object at 0x7fbcbc0fd850>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
      "/home/adam/anaconda3/lib/python3.8/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'harcerz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=5, min_count=1)\n",
    "print(model)\n",
    "print(model.vocabulary)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model jest niezwykle mały i niezbyt praktyczny, ale pozwolił pokazać podstawę uczenia word2vec. Przy większych korpusach tekstowych wczytywanie do pamięci wielkich tablic nie byłoby najlepszym pomysłem. Na szczęście implementacja word2vec w gensim potrafi przetwarzać dane przyrostowo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie strumieniowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast wczytywać wszystkie dokumenty naraz można robić to partiami, bo sieci neuronowe (w tym word2vec) potrafią douczać się przyrostowo. Do douczania przyrostowego świetnie nada się pythonowy iterator lub generator. Jeśli nie kojarzysz na czym polega działanie iteratorów i generatorów, zobacz jak [wyjaśnia to Radim Rehurek](https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/).\n",
    "\n",
    "Zasymulujmy zdania/wersy/tweety przechowywane w osobnych plikach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open, os\n",
    "\n",
    "if not os.path.exists('./data/'):\n",
    "    os.makedirs('./data/')\n",
    "\n",
    "filenames = ['./data/f' + str(i) +'.txt' for i in range(39)]\n",
    "\n",
    "if sentences is not None:\n",
    "    for i, fname in enumerate(filenames):\n",
    "        with smart_open.smart_open(fname, 'w') as fout:\n",
    "            for line in sentences[i]:\n",
    "                fout.write(line + ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3: Mając powyższy zbiór dokumentów tekstowych, stwórz metodę która będzie \"leniwie\" iterowała przez zasymulowany zbiór danych. Podczas iterowania usuń znaki interpunkcyjne i zmień wszystkie litery na małe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:42,760 : INFO : collecting all words and their counts\n",
      "2021-01-21 23:39:42,762 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 23:39:42,768 : INFO : collected 66 word types from a corpus of 183 raw words and 39 sentences\n",
      "2021-01-21 23:39:42,768 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 23:39:42,769 : INFO : effective_min_count=1 retains 66 unique words (100% of original 66, drops 0)\n",
      "2021-01-21 23:39:42,769 : INFO : effective_min_count=1 leaves 183 word corpus (100% of original 183, drops 0)\n",
      "2021-01-21 23:39:42,770 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2021-01-21 23:39:42,770 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2021-01-21 23:39:42,770 : INFO : downsampling leaves estimated 53 word corpus (29.5% of prior 183)\n",
      "2021-01-21 23:39:42,771 : INFO : estimated required memory for 66 words and 100 dimensions: 85800 bytes\n",
      "2021-01-21 23:39:42,771 : INFO : resetting layer weights\n",
      "2021-01-21 23:39:42,793 : INFO : training model with 3 workers on 66 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 23:39:42,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,801 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,801 : INFO : EPOCH - 1 : training on 183 raw words (49 effective words) took 0.0s, 8037 effective words/s\n",
      "2021-01-21 23:39:42,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,809 : INFO : EPOCH - 2 : training on 183 raw words (53 effective words) took 0.0s, 10047 effective words/s\n",
      "2021-01-21 23:39:42,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,817 : INFO : EPOCH - 3 : training on 183 raw words (51 effective words) took 0.0s, 10396 effective words/s\n",
      "2021-01-21 23:39:42,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,823 : INFO : EPOCH - 4 : training on 183 raw words (42 effective words) took 0.0s, 11176 effective words/s\n",
      "2021-01-21 23:39:42,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,832 : INFO : EPOCH - 5 : training on 183 raw words (46 effective words) took 0.0s, 7255 effective words/s\n",
      "2021-01-21 23:39:42,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,838 : INFO : EPOCH - 6 : training on 183 raw words (62 effective words) took 0.0s, 15164 effective words/s\n",
      "2021-01-21 23:39:42,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,848 : INFO : EPOCH - 7 : training on 183 raw words (61 effective words) took 0.0s, 8845 effective words/s\n",
      "2021-01-21 23:39:42,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,854 : INFO : EPOCH - 8 : training on 183 raw words (49 effective words) took 0.0s, 13106 effective words/s\n",
      "2021-01-21 23:39:42,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,861 : INFO : EPOCH - 9 : training on 183 raw words (52 effective words) took 0.0s, 12621 effective words/s\n",
      "2021-01-21 23:39:42,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:42,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:42,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:42,866 : INFO : EPOCH - 10 : training on 183 raw words (57 effective words) took 0.0s, 13830 effective words/s\n",
      "2021-01-21 23:39:42,867 : INFO : training on a 1830 raw words (522 effective words) took 0.1s, 7150 effective words/s\n",
      "2021-01-21 23:39:42,867 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-01-21 23:39:42,868 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=66, size=100, alpha=0.025)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'las'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            if fname.endswith('.txt'):\n",
    "                for line in open(os.path.join(self.dirname, fname)):\n",
    "                    yield line.translate(table).lower().split(\" \") \n",
    "\n",
    "# Do odkomentowania:\n",
    "sentences = MySentences('./data/')\n",
    "model = gensim.models.Word2Vec(sentences, iter=10, min_count=1)\n",
    "print(model)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trochę więcej danych i przykłady zastosowań\n",
    "\n",
    "Jak wspomniano wcześniej powyższa piosenka jest zbyt krótka by stworzyć przekonujący model podobieństwa między słowami. Przejdziemy teraz na język angielski i wykorzystamy korpus dołączony do biblioteki `gensim`. Ten korpus nie jest jeszcze duży, więc wyniki nie będą rewelacyjne. Potrzeba > 500 tys. słów, żeby oczekiwać rozsądnych wyników dla ogólnych zapytań, ale przy specjalistycznych zastosowaniach korpusy niekoniecznie muszą być takie duże.\n",
    "\n",
    "**Zad. 4: Korzystając ze zdobytej wiedzy na temat iteratorów, uzupełnij poniższy kod.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep\n",
    "lee_train_file = test_data_dir + 'lee_background.cor'\n",
    "\n",
    "class MyText(object):\n",
    "    def __iter__(self):\n",
    "        for line in open(lee_train_file):\n",
    "            # Załóż, że każda linia to dokument, zmień litery na małe,\n",
    "            # usuń podstawowe znaki interpunkcyjne i podziel według białych znaków\n",
    "            yield line.translate(table).lower().split(\" \")\n",
    "\n",
    "sentences = MyText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Naucz model word2vec o rozmiarze 200, przez 100 epok, usuwając słowa występującerzadziej niż 5 razy. Wynik przypisz do zmiennej `model`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:43,476 : INFO : collecting all words and their counts\n",
      "2021-01-21 23:39:43,481 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 23:39:43,502 : INFO : collected 7587 word types from a corpus of 60244 raw words and 300 sentences\n",
      "2021-01-21 23:39:43,503 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 23:39:43,510 : INFO : effective_min_count=5 retains 1792 unique words (23% of original 7587, drops 5795)\n",
      "2021-01-21 23:39:43,511 : INFO : effective_min_count=5 leaves 50650 word corpus (84% of original 60244, drops 9594)\n",
      "2021-01-21 23:39:43,519 : INFO : deleting the raw counts dictionary of 7587 items\n",
      "2021-01-21 23:39:43,520 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2021-01-21 23:39:43,521 : INFO : downsampling leaves estimated 36474 word corpus (72.0% of prior 50650)\n",
      "2021-01-21 23:39:43,525 : INFO : estimated required memory for 1792 words and 200 dimensions: 3763200 bytes\n",
      "2021-01-21 23:39:43,525 : INFO : resetting layer weights\n",
      "2021-01-21 23:39:43,946 : INFO : training model with 3 workers on 1792 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 23:39:44,004 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,018 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,019 : INFO : EPOCH - 1 : training on 60244 raw words (36481 effective words) took 0.1s, 518340 effective words/s\n",
      "2021-01-21 23:39:44,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,091 : INFO : EPOCH - 2 : training on 60244 raw words (36497 effective words) took 0.1s, 526098 effective words/s\n",
      "2021-01-21 23:39:44,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,149 : INFO : EPOCH - 3 : training on 60244 raw words (36474 effective words) took 0.1s, 649407 effective words/s\n",
      "2021-01-21 23:39:44,202 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,210 : INFO : EPOCH - 4 : training on 60244 raw words (36575 effective words) took 0.1s, 621778 effective words/s\n",
      "2021-01-21 23:39:44,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,272 : INFO : EPOCH - 5 : training on 60244 raw words (36554 effective words) took 0.1s, 606916 effective words/s\n",
      "2021-01-21 23:39:44,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,331 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,332 : INFO : EPOCH - 6 : training on 60244 raw words (36567 effective words) took 0.1s, 630748 effective words/s\n",
      "2021-01-21 23:39:44,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,388 : INFO : EPOCH - 7 : training on 60244 raw words (36491 effective words) took 0.1s, 672793 effective words/s\n",
      "2021-01-21 23:39:44,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,452 : INFO : EPOCH - 8 : training on 60244 raw words (36414 effective words) took 0.1s, 594268 effective words/s\n",
      "2021-01-21 23:39:44,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,510 : INFO : EPOCH - 9 : training on 60244 raw words (36524 effective words) took 0.1s, 646940 effective words/s\n",
      "2021-01-21 23:39:44,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,586 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,587 : INFO : EPOCH - 10 : training on 60244 raw words (36516 effective words) took 0.1s, 487060 effective words/s\n",
      "2021-01-21 23:39:44,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,656 : INFO : EPOCH - 11 : training on 60244 raw words (36389 effective words) took 0.1s, 542601 effective words/s\n",
      "2021-01-21 23:39:44,708 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,724 : INFO : EPOCH - 12 : training on 60244 raw words (36495 effective words) took 0.1s, 556891 effective words/s\n",
      "2021-01-21 23:39:44,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,794 : INFO : EPOCH - 13 : training on 60244 raw words (36367 effective words) took 0.1s, 542008 effective words/s\n",
      "2021-01-21 23:39:44,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,855 : INFO : EPOCH - 14 : training on 60244 raw words (36495 effective words) took 0.1s, 621736 effective words/s\n",
      "2021-01-21 23:39:44,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,912 : INFO : EPOCH - 15 : training on 60244 raw words (36418 effective words) took 0.1s, 652077 effective words/s\n",
      "2021-01-21 23:39:44,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:44,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:44,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:44,978 : INFO : EPOCH - 16 : training on 60244 raw words (36494 effective words) took 0.1s, 566368 effective words/s\n",
      "2021-01-21 23:39:45,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,039 : INFO : EPOCH - 17 : training on 60244 raw words (36614 effective words) took 0.1s, 626192 effective words/s\n",
      "2021-01-21 23:39:45,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:45,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,102 : INFO : EPOCH - 18 : training on 60244 raw words (36477 effective words) took 0.1s, 592577 effective words/s\n",
      "2021-01-21 23:39:45,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,168 : INFO : EPOCH - 19 : training on 60244 raw words (36389 effective words) took 0.1s, 565541 effective words/s\n",
      "2021-01-21 23:39:45,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,232 : INFO : EPOCH - 20 : training on 60244 raw words (36479 effective words) took 0.1s, 586171 effective words/s\n",
      "2021-01-21 23:39:45,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,295 : INFO : EPOCH - 21 : training on 60244 raw words (36511 effective words) took 0.1s, 605737 effective words/s\n",
      "2021-01-21 23:39:45,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,355 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,355 : INFO : EPOCH - 22 : training on 60244 raw words (36495 effective words) took 0.1s, 623389 effective words/s\n",
      "2021-01-21 23:39:45,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,412 : INFO : EPOCH - 23 : training on 60244 raw words (36443 effective words) took 0.1s, 661242 effective words/s\n",
      "2021-01-21 23:39:45,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,471 : INFO : EPOCH - 24 : training on 60244 raw words (36639 effective words) took 0.1s, 641123 effective words/s\n",
      "2021-01-21 23:39:45,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,538 : INFO : EPOCH - 25 : training on 60244 raw words (36518 effective words) took 0.1s, 559558 effective words/s\n",
      "2021-01-21 23:39:45,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,603 : INFO : EPOCH - 26 : training on 60244 raw words (36391 effective words) took 0.1s, 574089 effective words/s\n",
      "2021-01-21 23:39:45,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,667 : INFO : EPOCH - 27 : training on 60244 raw words (36494 effective words) took 0.1s, 588568 effective words/s\n",
      "2021-01-21 23:39:45,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,726 : INFO : EPOCH - 28 : training on 60244 raw words (36502 effective words) took 0.1s, 651858 effective words/s\n",
      "2021-01-21 23:39:45,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,783 : INFO : EPOCH - 29 : training on 60244 raw words (36549 effective words) took 0.1s, 659600 effective words/s\n",
      "2021-01-21 23:39:45,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,844 : INFO : EPOCH - 30 : training on 60244 raw words (36565 effective words) took 0.1s, 618675 effective words/s\n",
      "2021-01-21 23:39:45,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,910 : INFO : EPOCH - 31 : training on 60244 raw words (36558 effective words) took 0.1s, 566596 effective words/s\n",
      "2021-01-21 23:39:45,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:45,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:45,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:45,970 : INFO : EPOCH - 32 : training on 60244 raw words (36557 effective words) took 0.1s, 641785 effective words/s\n",
      "2021-01-21 23:39:46,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,035 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,040 : INFO : EPOCH - 33 : training on 60244 raw words (36514 effective words) took 0.1s, 535589 effective words/s\n",
      "2021-01-21 23:39:46,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,103 : INFO : EPOCH - 34 : training on 60244 raw words (36459 effective words) took 0.1s, 610079 effective words/s\n",
      "2021-01-21 23:39:46,147 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,151 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,156 : INFO : EPOCH - 35 : training on 60244 raw words (36486 effective words) took 0.1s, 713869 effective words/s\n",
      "2021-01-21 23:39:46,211 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,222 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,225 : INFO : EPOCH - 36 : training on 60244 raw words (36433 effective words) took 0.1s, 540033 effective words/s\n",
      "2021-01-21 23:39:46,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,284 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,292 : INFO : EPOCH - 37 : training on 60244 raw words (36337 effective words) took 0.1s, 570620 effective words/s\n",
      "2021-01-21 23:39:46,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:46,352 : INFO : EPOCH - 38 : training on 60244 raw words (36571 effective words) took 0.1s, 628148 effective words/s\n",
      "2021-01-21 23:39:46,403 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,411 : INFO : EPOCH - 39 : training on 60244 raw words (36427 effective words) took 0.1s, 646411 effective words/s\n",
      "2021-01-21 23:39:46,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,479 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,481 : INFO : EPOCH - 40 : training on 60244 raw words (36516 effective words) took 0.1s, 550080 effective words/s\n",
      "2021-01-21 23:39:46,530 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,539 : INFO : EPOCH - 41 : training on 60244 raw words (36511 effective words) took 0.1s, 661594 effective words/s\n",
      "2021-01-21 23:39:46,592 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,598 : INFO : EPOCH - 42 : training on 60244 raw words (36361 effective words) took 0.1s, 644628 effective words/s\n",
      "2021-01-21 23:39:46,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,666 : INFO : EPOCH - 43 : training on 60244 raw words (36517 effective words) took 0.1s, 555060 effective words/s\n",
      "2021-01-21 23:39:46,721 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,722 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,728 : INFO : EPOCH - 44 : training on 60244 raw words (36470 effective words) took 0.1s, 610027 effective words/s\n",
      "2021-01-21 23:39:46,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,789 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,790 : INFO : EPOCH - 45 : training on 60244 raw words (36431 effective words) took 0.1s, 606849 effective words/s\n",
      "2021-01-21 23:39:46,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,850 : INFO : EPOCH - 46 : training on 60244 raw words (36561 effective words) took 0.1s, 624519 effective words/s\n",
      "2021-01-21 23:39:46,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,918 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,919 : INFO : EPOCH - 47 : training on 60244 raw words (36525 effective words) took 0.1s, 550229 effective words/s\n",
      "2021-01-21 23:39:46,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:46,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:46,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:46,980 : INFO : EPOCH - 48 : training on 60244 raw words (36377 effective words) took 0.1s, 605406 effective words/s\n",
      "2021-01-21 23:39:47,033 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,046 : INFO : EPOCH - 49 : training on 60244 raw words (36473 effective words) took 0.1s, 572636 effective words/s\n",
      "2021-01-21 23:39:47,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,118 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,119 : INFO : EPOCH - 50 : training on 60244 raw words (36373 effective words) took 0.1s, 520617 effective words/s\n",
      "2021-01-21 23:39:47,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,174 : INFO : EPOCH - 51 : training on 60244 raw words (36445 effective words) took 0.1s, 691012 effective words/s\n",
      "2021-01-21 23:39:47,226 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,233 : INFO : EPOCH - 52 : training on 60244 raw words (36452 effective words) took 0.1s, 646420 effective words/s\n",
      "2021-01-21 23:39:47,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,292 : INFO : EPOCH - 53 : training on 60244 raw words (36517 effective words) took 0.1s, 637510 effective words/s\n",
      "2021-01-21 23:39:47,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,352 : INFO : EPOCH - 54 : training on 60244 raw words (36354 effective words) took 0.1s, 622624 effective words/s\n",
      "2021-01-21 23:39:47,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,408 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,408 : INFO : EPOCH - 55 : training on 60244 raw words (36582 effective words) took 0.1s, 671036 effective words/s\n",
      "2021-01-21 23:39:47,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,472 : INFO : EPOCH - 56 : training on 60244 raw words (36485 effective words) took 0.1s, 585151 effective words/s\n",
      "2021-01-21 23:39:47,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,535 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,536 : INFO : EPOCH - 57 : training on 60244 raw words (36458 effective words) took 0.1s, 593622 effective words/s\n",
      "2021-01-21 23:39:47,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,602 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,603 : INFO : EPOCH - 58 : training on 60244 raw words (36465 effective words) took 0.1s, 568105 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:47,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,662 : INFO : EPOCH - 59 : training on 60244 raw words (36482 effective words) took 0.1s, 644227 effective words/s\n",
      "2021-01-21 23:39:47,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,728 : INFO : EPOCH - 60 : training on 60244 raw words (36505 effective words) took 0.1s, 568740 effective words/s\n",
      "2021-01-21 23:39:47,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,799 : INFO : EPOCH - 61 : training on 60244 raw words (36499 effective words) took 0.1s, 532332 effective words/s\n",
      "2021-01-21 23:39:47,855 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,866 : INFO : EPOCH - 62 : training on 60244 raw words (36505 effective words) took 0.1s, 570094 effective words/s\n",
      "2021-01-21 23:39:47,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,927 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,928 : INFO : EPOCH - 63 : training on 60244 raw words (36515 effective words) took 0.1s, 599027 effective words/s\n",
      "2021-01-21 23:39:47,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:47,995 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:47,997 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:47,997 : INFO : EPOCH - 64 : training on 60244 raw words (36550 effective words) took 0.1s, 547157 effective words/s\n",
      "2021-01-21 23:39:48,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,059 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,074 : INFO : EPOCH - 65 : training on 60244 raw words (36580 effective words) took 0.1s, 486772 effective words/s\n",
      "2021-01-21 23:39:48,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,135 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,139 : INFO : EPOCH - 66 : training on 60244 raw words (36647 effective words) took 0.1s, 588372 effective words/s\n",
      "2021-01-21 23:39:48,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,200 : INFO : EPOCH - 67 : training on 60244 raw words (36477 effective words) took 0.1s, 620223 effective words/s\n",
      "2021-01-21 23:39:48,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,271 : INFO : EPOCH - 68 : training on 60244 raw words (36456 effective words) took 0.1s, 525928 effective words/s\n",
      "2021-01-21 23:39:48,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,328 : INFO : EPOCH - 69 : training on 60244 raw words (36421 effective words) took 0.1s, 677074 effective words/s\n",
      "2021-01-21 23:39:48,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,393 : INFO : EPOCH - 70 : training on 60244 raw words (36484 effective words) took 0.1s, 588431 effective words/s\n",
      "2021-01-21 23:39:48,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,459 : INFO : EPOCH - 71 : training on 60244 raw words (36430 effective words) took 0.1s, 573378 effective words/s\n",
      "2021-01-21 23:39:48,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,529 : INFO : EPOCH - 72 : training on 60244 raw words (36495 effective words) took 0.1s, 541688 effective words/s\n",
      "2021-01-21 23:39:48,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,585 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,590 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,591 : INFO : EPOCH - 73 : training on 60244 raw words (36574 effective words) took 0.1s, 600748 effective words/s\n",
      "2021-01-21 23:39:48,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,657 : INFO : EPOCH - 74 : training on 60244 raw words (36487 effective words) took 0.1s, 565257 effective words/s\n",
      "2021-01-21 23:39:48,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,716 : INFO : EPOCH - 75 : training on 60244 raw words (36602 effective words) took 0.1s, 643512 effective words/s\n",
      "2021-01-21 23:39:48,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,785 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,786 : INFO : EPOCH - 76 : training on 60244 raw words (36434 effective words) took 0.1s, 539552 effective words/s\n",
      "2021-01-21 23:39:48,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,849 : INFO : EPOCH - 77 : training on 60244 raw words (36558 effective words) took 0.1s, 595244 effective words/s\n",
      "2021-01-21 23:39:48,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:48,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,913 : INFO : EPOCH - 78 : training on 60244 raw words (36521 effective words) took 0.1s, 600249 effective words/s\n",
      "2021-01-21 23:39:48,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:48,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:48,982 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:48,983 : INFO : EPOCH - 79 : training on 60244 raw words (36507 effective words) took 0.1s, 545862 effective words/s\n",
      "2021-01-21 23:39:49,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,041 : INFO : EPOCH - 80 : training on 60244 raw words (36385 effective words) took 0.1s, 636751 effective words/s\n",
      "2021-01-21 23:39:49,093 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,102 : INFO : EPOCH - 81 : training on 60244 raw words (36470 effective words) took 0.1s, 619944 effective words/s\n",
      "2021-01-21 23:39:49,150 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,160 : INFO : EPOCH - 82 : training on 60244 raw words (36478 effective words) took 0.1s, 652490 effective words/s\n",
      "2021-01-21 23:39:49,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,224 : INFO : EPOCH - 83 : training on 60244 raw words (36454 effective words) took 0.1s, 588813 effective words/s\n",
      "2021-01-21 23:39:49,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,280 : INFO : EPOCH - 84 : training on 60244 raw words (36495 effective words) took 0.1s, 678532 effective words/s\n",
      "2021-01-21 23:39:49,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,345 : INFO : EPOCH - 85 : training on 60244 raw words (36495 effective words) took 0.1s, 579128 effective words/s\n",
      "2021-01-21 23:39:49,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,404 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,408 : INFO : EPOCH - 86 : training on 60244 raw words (36496 effective words) took 0.1s, 600330 effective words/s\n",
      "2021-01-21 23:39:49,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,472 : INFO : EPOCH - 87 : training on 60244 raw words (36488 effective words) took 0.1s, 589571 effective words/s\n",
      "2021-01-21 23:39:49,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,537 : INFO : EPOCH - 88 : training on 60244 raw words (36418 effective words) took 0.1s, 588636 effective words/s\n",
      "2021-01-21 23:39:49,587 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,593 : INFO : EPOCH - 89 : training on 60244 raw words (36486 effective words) took 0.1s, 657315 effective words/s\n",
      "2021-01-21 23:39:49,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,651 : INFO : EPOCH - 90 : training on 60244 raw words (36490 effective words) took 0.1s, 649014 effective words/s\n",
      "2021-01-21 23:39:49,703 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,704 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,709 : INFO : EPOCH - 91 : training on 60244 raw words (36498 effective words) took 0.1s, 652992 effective words/s\n",
      "2021-01-21 23:39:49,767 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,768 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,775 : INFO : EPOCH - 92 : training on 60244 raw words (36486 effective words) took 0.1s, 572144 effective words/s\n",
      "2021-01-21 23:39:49,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,833 : INFO : EPOCH - 93 : training on 60244 raw words (36492 effective words) took 0.1s, 653386 effective words/s\n",
      "2021-01-21 23:39:49,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,907 : INFO : EPOCH - 94 : training on 60244 raw words (36505 effective words) took 0.1s, 512268 effective words/s\n",
      "2021-01-21 23:39:49,960 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:49,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:49,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:49,977 : INFO : EPOCH - 95 : training on 60244 raw words (36490 effective words) took 0.1s, 553697 effective words/s\n",
      "2021-01-21 23:39:50,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:50,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:50,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:50,048 : INFO : EPOCH - 96 : training on 60244 raw words (36502 effective words) took 0.1s, 536443 effective words/s\n",
      "2021-01-21 23:39:50,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:50,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:50,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:50,108 : INFO : EPOCH - 97 : training on 60244 raw words (36377 effective words) took 0.1s, 640274 effective words/s\n",
      "2021-01-21 23:39:50,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:50,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:50,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:50,166 : INFO : EPOCH - 98 : training on 60244 raw words (36505 effective words) took 0.1s, 650260 effective words/s\n",
      "2021-01-21 23:39:50,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:50,223 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:50,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:50,230 : INFO : EPOCH - 99 : training on 60244 raw words (36370 effective words) took 0.1s, 584260 effective words/s\n",
      "2021-01-21 23:39:50,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 23:39:50,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 23:39:50,293 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 23:39:50,293 : INFO : EPOCH - 100 : training on 60244 raw words (36469 effective words) took 0.1s, 595041 effective words/s\n",
      "2021-01-21 23:39:50,293 : INFO : training on a 6024400 raw words (3648610 effective words) took 6.3s, 574876 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=1792, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=100, min_count=5, size=200)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6: Odkomentuj poniższe linie i zobacz jak można wykorzystać uzyskany model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:50,298 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rights', 0.5150513648986816)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['human', 'crime'], negative=['party'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:50,319 : WARNING : vectors for words {'cat', 'input', 'lunch'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"input is lunch he sentence cat\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.035116423\n",
      "0.27034813\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('human', 'tree'))\n",
    "print(model.wv.similarity('crime', 'murder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwagi dodatkowe:**\n",
    "+ uczenie modelu można zrównoleglić, ale trzeba doinstalować [Cythona](http://cython.org/)\n",
    "+ wytrenowany model można łatwo zapisać do pliku za pomocą: `model.save(path)`\n",
    "+ równie łatwo można go później wczytać: `model = gensim.models.Word2Vec.load(path)`\n",
    "+ ponieważ uczenie jest przyrostowe, można łatwo rozszerzyć istniejący słownik i douczyć model na nowych zdaniach:\n",
    "```\n",
    "model = gensim.models.Word2Vec.load(path)\n",
    "more_sentences = [['Advanced', 'users', 'can', 'load', 'a', 'model', 'and', 'continue', \n",
    "                  'training', 'it', 'with', 'more', 'sentences']]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystanie gotowego modelu do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Póki co sami trenowaliśmy word2vec i to na niedużych zbiorach danych. Na szczęście są już gotowe modele (przynajmniej dla języka angielskiego) nauczone na miliardach dokumentów i zawierające miliony słów. Przydatna lista takich modeli (wraz z kodem tworzącym usługę sieciową wykorzystującą model...) pod adresem: https://github.com/3Top/word2vec-api.\n",
    "\n",
    "**Zad. 7: Pobierz korpus Google News i zapisz pobrany plik do folderu data. Następnie wykonaj poniższy kod. Ta operacja zajmie jakieś 3-4 minuty i zużyje ok. 4 GB RAMU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:39:50,339 : INFO : loading projection weights from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2021-01-21 23:41:26,052 : INFO : loaded (3000000, 300) matrix from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2021-01-21 23:41:26,052 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 3.42 s, total: 2min 8s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 8: Zobacz jak działa model nauczony na tak dużym korpusie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192315101624)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664013\n",
      "0.32413524\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity('woman', 'man'))\n",
    "print(wv.similarity('woman', 'cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, super. Mam świetny model, mogę nim podpowiadać słowa, wynajdować niepasujące elementy, uzupełniać zdania, znajdować synonimy, itd. Ale czy da się to jakoś wykorzystać do klasyfikacji? word2vec ma wektor na każde słowo - jak z tego zrobić wektor na ciąg słów?\n",
    "\n",
    "**Odpowiedź: można uśrednić znaczenie słów w dokuemncie poprzez zsumowanie wektorów wszystkich słów.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo szybko spróbujemy zastosować to podejście do predykcji gatunku filmu na podstawie jego opisu. Poniżej kod wczytujący ciekawy zbiór danych oraz pokazujący jakie ma klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:41:59,824 : INFO : Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-01-21 23:41:59,825 : INFO : NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  movieId                                               plot  \\\n",
      "0           0        1  A little boy named Andy loves to be in his roo...   \n",
      "1           1        2  When two kids find and play a magical board ga...   \n",
      "2           2        3  Things don't seem to change much in Wabasha Co...   \n",
      "3           3        6  Hunters and their prey--Neil and his professio...   \n",
      "4           4        7  An ugly duckling having undergone a remarkable...   \n",
      "\n",
      "         tag  \n",
      "0  animation  \n",
      "1    fantasy  \n",
      "2     comedy  \n",
      "3     action  \n",
      "4    romance  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb7fab54c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('data/tagged_plots_movielens.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "df.tag.value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szybko dzielimy dane na zbiór uczący i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizujemy dane i wyliczamy reprezentację wektorową (za pomocą zsumowanych wektorów słów wrod2vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczymy i testujemy klasyfikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, train_data['tag'])\n",
    "predicted = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrzymy jak nam poszło:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.5390946502057613\n",
      "Macierz pomyłek\n",
      " [[23  2 10  0  1  6]\n",
      " [ 3 10  8  3  4  3]\n",
      " [ 2  5 55  2 18  4]\n",
      " [ 3  4  4  4  0  1]\n",
      " [ 4  0 12  1 16  2]\n",
      " [ 5  0  3  0  2 23]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.tag, predicted))\n",
    "cm = confusion_matrix(test_data.tag, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak na brak porządnego przetwarzania wstępnego, nie jest to zły wynik. Mam nadzieję, że ten przykład pokazał jak można wykorzystać word2vec do tworzenia atrybutów dla problemów klasyfikacyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
