{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# word2vec\n",
    "\n",
    "Ten notatnik ma na celu przedstawienie sposobu tworzenia i wykorzystania reprezentacji werktorowych na przykładzie algorytmu word2vec. W trakcie zadania najpierw stworzymy prostą reprezentację wektorową, a następnie spróbujemy wczytać gotowy model nauczony na dużym korpusie tekstowym.\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ wiedzieć na czym polega word2vec,\n",
    "+ potrafić stworzyć word2vec na własnych danych,\n",
    "+ potrafić wykorzystać word2vec do:\n",
    "\t+ znalezienia podobnych słów,\n",
    "\t+ wyszukiwania słów na zasadzie \"reguły trzech\", \n",
    "\t+ wykrywania niepasujących słów,\n",
    "\t+ do tworzenia wektora cech nadającego się do klasyfikacji,\n",
    "+ wczytać i wykorzystać gotowy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosty model\n",
    "\n",
    "Najpierw wczytamy odpowiednie biblioteki i stworzymy mały zbiór treningowy na podstawie znanej piosenki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, re, nltk\n",
    "import pandas as pd\n",
    "\n",
    "RE_SPACES = re.compile(\"\\s+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "song = \"\"\"Gdzie strumyk płynie z wolna,\n",
    "Rozsiewa zioła maj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Stokrotka rosła polna,\n",
    "A nad nią szumiał gaj,\n",
    "Zielony gaj.\n",
    "\n",
    "W tym gaju tak ponuro,\n",
    "Że aż przeraża mnie,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "Ptaszęta za wysoko,\n",
    "A mnie samotnej źle,\n",
    "samotnej źle.\n",
    "\n",
    "Wtem harcerz idzie z wolna.\n",
    "„Stokrotko, witam cię,\n",
    "Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?”\n",
    "\"Twój urok mnie zachwyca,\n",
    "Czy chcesz być mą, czy nie?\n",
    "Czy nie, czy nie?\n",
    "\n",
    "Stokrotka się zgodziła\n",
    "I poszli w ciemny las,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "A harcerz taki gapa\n",
    "że aż w pokrzywy wlazł,\n",
    "w pokrzywy wlazł.\n",
    "\n",
    "A ona, ona, ona,\n",
    "Cóż biedna robić ma,\n",
    "Nad gapą pochylona\n",
    "I śmieje się: ha, ha,\n",
    "Nad gapą pochylona\n",
    "I śmieje: się ha, ha,\n",
    "ha, ha, ha, ha.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1: Podziel piosenkę na wersy, a wersy tokenizuj spacjami. W efekcie powinieneś stworzyć listę list i przypisać ją do zmiennej `sentences`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gdzie', 'strumyk', 'płynie', 'z', 'wolna,'], ['Rozsiewa', 'zioła', 'maj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Stokrotka', 'rosła', 'polna,'], ['A', 'nad', 'nią', 'szumiał', 'gaj,'], ['Zielony', 'gaj.'], [''], ['W', 'tym', 'gaju', 'tak', 'ponuro,'], ['Że', 'aż', 'przeraża', 'mnie,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['Ptaszęta', 'za', 'wysoko,'], ['A', 'mnie', 'samotnej', 'źle,'], ['samotnej', 'źle.'], [''], ['Wtem', 'harcerz', 'idzie', 'z', 'wolna.'], ['„Stokrotko,', 'witam', 'cię,'], ['Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?”'], ['\"Twój', 'urok', 'mnie', 'zachwyca,'], ['Czy', 'chcesz', 'być', 'mą,', 'czy', 'nie?'], ['Czy', 'nie,', 'czy', 'nie?'], [''], ['Stokrotka', 'się', 'zgodziła'], ['I', 'poszli', 'w', 'ciemny', 'las,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['A', 'harcerz', 'taki', 'gapa'], ['że', 'aż', 'w', 'pokrzywy', 'wlazł,'], ['w', 'pokrzywy', 'wlazł.'], [''], ['A', 'ona,', 'ona,', 'ona,'], ['Cóż', 'biedna', 'robić', 'ma,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje', 'się:', 'ha,', 'ha,'], ['Nad', 'gapą', 'pochylona'], ['I', 'śmieje:', 'się', 'ha,', 'ha,'], ['ha,', 'ha,', 'ha,', 'ha.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = [re.split(RE_SPACES,verse) for verse in re.split(\"\\n\",song)]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając tekst podzielony na zdania a zdania na tokeny, możemy nauczyć model word2vec.\n",
    "\n",
    "**Zad. 2: Naucz model word2vec. [Sprawdź](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) za co odpowiedzialne są parametry `min_count` i `iter`. Jakie inne parametry mogą być przydatne?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:41:29,780 : INFO : collecting all words and their counts\n",
      "2021-01-21 22:41:29,781 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 22:41:29,782 : INFO : collected 80 word types from a corpus of 144 raw words and 39 sentences\n",
      "2021-01-21 22:41:29,782 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 22:41:29,783 : INFO : effective_min_count=1 retains 80 unique words (100% of original 80, drops 0)\n",
      "2021-01-21 22:41:29,784 : INFO : effective_min_count=1 leaves 144 word corpus (100% of original 144, drops 0)\n",
      "2021-01-21 22:41:29,785 : INFO : deleting the raw counts dictionary of 80 items\n",
      "2021-01-21 22:41:29,785 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2021-01-21 22:41:29,786 : INFO : downsampling leaves estimated 50 word corpus (35.2% of prior 144)\n",
      "2021-01-21 22:41:29,787 : INFO : estimated required memory for 80 words and 100 dimensions: 104000 bytes\n",
      "2021-01-21 22:41:29,788 : INFO : resetting layer weights\n",
      "2021-01-21 22:41:29,811 : INFO : training model with 3 workers on 80 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 22:41:29,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:41:29,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:41:29,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:41:29,816 : INFO : EPOCH - 1 : training on 144 raw words (48 effective words) took 0.0s, 17959 effective words/s\n",
      "2021-01-21 22:41:29,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:41:29,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:41:29,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:41:29,821 : INFO : EPOCH - 2 : training on 144 raw words (53 effective words) took 0.0s, 25119 effective words/s\n",
      "2021-01-21 22:41:29,824 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:41:29,824 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:41:29,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:41:29,825 : INFO : EPOCH - 3 : training on 144 raw words (47 effective words) took 0.0s, 26088 effective words/s\n",
      "2021-01-21 22:41:29,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:41:29,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:41:29,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:41:29,831 : INFO : EPOCH - 4 : training on 144 raw words (62 effective words) took 0.0s, 17376 effective words/s\n",
      "2021-01-21 22:41:29,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:41:29,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:41:29,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:41:29,837 : INFO : EPOCH - 5 : training on 144 raw words (51 effective words) took 0.0s, 19513 effective words/s\n",
      "2021-01-21 22:41:29,838 : INFO : training on a 720 raw words (261 effective words) took 0.0s, 9888 effective words/s\n",
      "2021-01-21 22:41:29,839 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-01-21 22:41:29,839 : INFO : precomputing L2-norms of word weight vectors\n",
      "2021-01-21 22:41:29,841 : WARNING : vectors for words {'las', 'gaj'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=80, size=100, alpha=0.025)\n",
      "<gensim.models.word2vec.Word2VecVocab object at 0x7fee6175fb80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zioła'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=5, min_count=1)\n",
    "print(model)\n",
    "print(model.vocabulary)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model jest niezwykle mały i niezbyt praktyczny, ale pozwolił pokazać podstawę uczenia word2vec. Przy większych korpusach tekstowych wczytywanie do pamięci wielkich tablic nie byłoby najlepszym pomysłem. Na szczęście implementacja word2vec w gensim potrafi przetwarzać dane przyrostowo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie strumieniowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast wczytywać wszystkie dokumenty naraz można robić to partiami, bo sieci neuronowe (w tym word2vec) potrafią douczać się przyrostowo. Do douczania przyrostowego świetnie nada się pythonowy iterator lub generator. Jeśli nie kojarzysz na czym polega działanie iteratorów i generatorów, zobacz jak [wyjaśnia to Radim Rehurek](https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/).\n",
    "\n",
    "Zasymulujmy zdania/wersy/tweety przechowywane w osobnych plikach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open, os\n",
    "\n",
    "if not os.path.exists('./data/'):\n",
    "    os.makedirs('./data/')\n",
    "\n",
    "filenames = ['./data/f' + str(i) +'.txt' for i in range(39)]\n",
    "\n",
    "if sentences is not None:\n",
    "    for i, fname in enumerate(filenames):\n",
    "        with smart_open.smart_open(fname, 'w') as fout:\n",
    "            for line in sentences[i]:\n",
    "                fout.write(line + ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3: Mając powyższy zbiór dokumentów tekstowych, stwórz metodę która będzie \"leniwie\" iterowała przez zasymulowany zbiór danych. Podczas iterowania usuń znaki interpunkcyjne i zmień wszystkie litery na małe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:52:28,822 : INFO : collecting all words and their counts\n",
      "2021-01-21 22:52:28,824 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 22:52:28,827 : INFO : collected 66 word types from a corpus of 183 raw words and 39 sentences\n",
      "2021-01-21 22:52:28,828 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 22:52:28,829 : INFO : effective_min_count=1 retains 66 unique words (100% of original 66, drops 0)\n",
      "2021-01-21 22:52:28,829 : INFO : effective_min_count=1 leaves 183 word corpus (100% of original 183, drops 0)\n",
      "2021-01-21 22:52:28,831 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2021-01-21 22:52:28,832 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2021-01-21 22:52:28,832 : INFO : downsampling leaves estimated 53 word corpus (29.5% of prior 183)\n",
      "2021-01-21 22:52:28,833 : INFO : estimated required memory for 66 words and 100 dimensions: 85800 bytes\n",
      "2021-01-21 22:52:28,833 : INFO : resetting layer weights\n",
      "2021-01-21 22:52:28,857 : INFO : training model with 3 workers on 66 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 22:52:28,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,867 : INFO : EPOCH - 1 : training on 183 raw words (49 effective words) took 0.0s, 6292 effective words/s\n",
      "2021-01-21 22:52:28,872 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,874 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,874 : INFO : EPOCH - 2 : training on 183 raw words (53 effective words) took 0.0s, 10935 effective words/s\n",
      "2021-01-21 22:52:28,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,881 : INFO : EPOCH - 3 : training on 183 raw words (51 effective words) took 0.0s, 9815 effective words/s\n",
      "2021-01-21 22:52:28,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,891 : INFO : EPOCH - 4 : training on 183 raw words (42 effective words) took 0.0s, 6603 effective words/s\n",
      "2021-01-21 22:52:28,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,898 : INFO : EPOCH - 5 : training on 183 raw words (46 effective words) took 0.0s, 9333 effective words/s\n",
      "2021-01-21 22:52:28,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,906 : INFO : EPOCH - 6 : training on 183 raw words (62 effective words) took 0.0s, 10539 effective words/s\n",
      "2021-01-21 22:52:28,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,914 : INFO : EPOCH - 7 : training on 183 raw words (61 effective words) took 0.0s, 14248 effective words/s\n",
      "2021-01-21 22:52:28,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,919 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,921 : INFO : EPOCH - 8 : training on 183 raw words (49 effective words) took 0.0s, 9243 effective words/s\n",
      "2021-01-21 22:52:28,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,926 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,927 : INFO : EPOCH - 9 : training on 183 raw words (52 effective words) took 0.0s, 13232 effective words/s\n",
      "2021-01-21 22:52:28,933 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:52:28,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:52:28,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:52:28,936 : INFO : EPOCH - 10 : training on 183 raw words (57 effective words) took 0.0s, 7933 effective words/s\n",
      "2021-01-21 22:52:28,936 : INFO : training on a 1830 raw words (522 effective words) took 0.1s, 6662 effective words/s\n",
      "2021-01-21 22:52:28,937 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-01-21 22:52:28,938 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=66, size=100, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'las'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            if fname.endswith('.txt'):\n",
    "                for line in open(os.path.join(self.dirname, fname)):\n",
    "                    yield line.translate(table).lower().split(\" \") \n",
    "\n",
    "# Do odkomentowania:\n",
    "sentences = MySentences('./data/')\n",
    "model = gensim.models.Word2Vec(sentences, iter=10, min_count=1)\n",
    "print(model)\n",
    "\n",
    "model.wv.doesnt_match(\"las harcerz gaj zioła\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trochę więcej danych i przykłady zastosowań\n",
    "\n",
    "Jak wspomniano wcześniej powyższa piosenka jest zbyt krótka by stworzyć przekonujący model podobieństwa między słowami. Przejdziemy teraz na język angielski i wykorzystamy korpus dołączony do biblioteki `gensim`. Ten korpus nie jest jeszcze duży, więc wyniki nie będą rewelacyjne. Potrzeba > 500 tys. słów, żeby oczekiwać rozsądnych wyników dla ogólnych zapytań, ale przy specjalistycznych zastosowaniach korpusy niekoniecznie muszą być takie duże.\n",
    "\n",
    "**Zad. 4: Korzystając ze zdobytej wiedzy na temat iteratorów, uzupełnij poniższy kod.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep\n",
    "lee_train_file = test_data_dir + 'lee_background.cor'\n",
    "\n",
    "class MyText(object):\n",
    "    def __iter__(self):\n",
    "        for line in open(lee_train_file):\n",
    "            # Załóż, że każda linia to dokument, zmień litery na małe,\n",
    "            # usuń podstawowe znaki interpunkcyjne i podziel według białych znaków\n",
    "            yield line.translate(table).lower().split(\" \")\n",
    "\n",
    "sentences = MyText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Naucz model word2vec o rozmiarze 200, przez 100 epok, usuwając słowa występującerzadziej niż 5 razy. Wynik przypisz do zmiennej `model`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:49,967 : INFO : collecting all words and their counts\n",
      "2021-01-21 22:54:49,971 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-21 22:54:49,998 : INFO : collected 7587 word types from a corpus of 60244 raw words and 300 sentences\n",
      "2021-01-21 22:54:49,999 : INFO : Loading a fresh vocabulary\n",
      "2021-01-21 22:54:50,015 : INFO : effective_min_count=5 retains 1792 unique words (23% of original 7587, drops 5795)\n",
      "2021-01-21 22:54:50,016 : INFO : effective_min_count=5 leaves 50650 word corpus (84% of original 60244, drops 9594)\n",
      "2021-01-21 22:54:50,025 : INFO : deleting the raw counts dictionary of 7587 items\n",
      "2021-01-21 22:54:50,027 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2021-01-21 22:54:50,027 : INFO : downsampling leaves estimated 36474 word corpus (72.0% of prior 50650)\n",
      "2021-01-21 22:54:50,033 : INFO : estimated required memory for 1792 words and 200 dimensions: 3763200 bytes\n",
      "2021-01-21 22:54:50,034 : INFO : resetting layer weights\n",
      "2021-01-21 22:54:50,445 : INFO : training model with 3 workers on 1792 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-01-21 22:54:50,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,512 : INFO : EPOCH - 1 : training on 60244 raw words (36480 effective words) took 0.1s, 562729 effective words/s\n",
      "2021-01-21 22:54:50,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,583 : INFO : EPOCH - 2 : training on 60244 raw words (36584 effective words) took 0.1s, 530343 effective words/s\n",
      "2021-01-21 22:54:50,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,651 : INFO : EPOCH - 3 : training on 60244 raw words (36512 effective words) took 0.1s, 556350 effective words/s\n",
      "2021-01-21 22:54:50,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,707 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,710 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,712 : INFO : EPOCH - 4 : training on 60244 raw words (36494 effective words) took 0.1s, 620345 effective words/s\n",
      "2021-01-21 22:54:50,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,767 : INFO : EPOCH - 5 : training on 60244 raw words (36524 effective words) took 0.1s, 680160 effective words/s\n",
      "2021-01-21 22:54:50,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,829 : INFO : EPOCH - 6 : training on 60244 raw words (36454 effective words) took 0.1s, 604978 effective words/s\n",
      "2021-01-21 22:54:50,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,900 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,901 : INFO : EPOCH - 7 : training on 60244 raw words (36424 effective words) took 0.1s, 533511 effective words/s\n",
      "2021-01-21 22:54:50,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:50,959 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:50,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:50,963 : INFO : EPOCH - 8 : training on 60244 raw words (36464 effective words) took 0.1s, 595223 effective words/s\n",
      "2021-01-21 22:54:51,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,030 : INFO : EPOCH - 9 : training on 60244 raw words (36420 effective words) took 0.1s, 568913 effective words/s\n",
      "2021-01-21 22:54:51,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,099 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,100 : INFO : EPOCH - 10 : training on 60244 raw words (36536 effective words) took 0.1s, 538189 effective words/s\n",
      "2021-01-21 22:54:51,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,158 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,158 : INFO : EPOCH - 11 : training on 60244 raw words (36604 effective words) took 0.1s, 646856 effective words/s\n",
      "2021-01-21 22:54:51,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,223 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,228 : INFO : EPOCH - 12 : training on 60244 raw words (36451 effective words) took 0.1s, 551788 effective words/s\n",
      "2021-01-21 22:54:51,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,301 : INFO : EPOCH - 13 : training on 60244 raw words (36373 effective words) took 0.1s, 511684 effective words/s\n",
      "2021-01-21 22:54:51,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,365 : INFO : EPOCH - 14 : training on 60244 raw words (36503 effective words) took 0.1s, 585681 effective words/s\n",
      "2021-01-21 22:54:51,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,432 : INFO : EPOCH - 15 : training on 60244 raw words (36500 effective words) took 0.1s, 565674 effective words/s\n",
      "2021-01-21 22:54:51,479 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,493 : INFO : EPOCH - 16 : training on 60244 raw words (36436 effective words) took 0.1s, 611766 effective words/s\n",
      "2021-01-21 22:54:51,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,545 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,549 : INFO : EPOCH - 17 : training on 60244 raw words (36468 effective words) took 0.1s, 689867 effective words/s\n",
      "2021-01-21 22:54:51,597 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,601 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:51,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,605 : INFO : EPOCH - 18 : training on 60244 raw words (36468 effective words) took 0.1s, 662101 effective words/s\n",
      "2021-01-21 22:54:51,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,663 : INFO : EPOCH - 19 : training on 60244 raw words (36471 effective words) took 0.1s, 654073 effective words/s\n",
      "2021-01-21 22:54:51,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,736 : INFO : EPOCH - 20 : training on 60244 raw words (36444 effective words) took 0.1s, 516249 effective words/s\n",
      "2021-01-21 22:54:51,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,797 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,799 : INFO : EPOCH - 21 : training on 60244 raw words (36483 effective words) took 0.1s, 589923 effective words/s\n",
      "2021-01-21 22:54:51,853 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,865 : INFO : EPOCH - 22 : training on 60244 raw words (36458 effective words) took 0.1s, 567257 effective words/s\n",
      "2021-01-21 22:54:51,915 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,926 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,927 : INFO : EPOCH - 23 : training on 60244 raw words (36564 effective words) took 0.1s, 609540 effective words/s\n",
      "2021-01-21 22:54:51,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:51,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:51,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:51,997 : INFO : EPOCH - 24 : training on 60244 raw words (36449 effective words) took 0.1s, 529925 effective words/s\n",
      "2021-01-21 22:54:52,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,062 : INFO : EPOCH - 25 : training on 60244 raw words (36461 effective words) took 0.1s, 576729 effective words/s\n",
      "2021-01-21 22:54:52,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,123 : INFO : EPOCH - 26 : training on 60244 raw words (36427 effective words) took 0.1s, 610885 effective words/s\n",
      "2021-01-21 22:54:52,176 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,191 : INFO : EPOCH - 27 : training on 60244 raw words (36369 effective words) took 0.1s, 553295 effective words/s\n",
      "2021-01-21 22:54:52,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,257 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,258 : INFO : EPOCH - 28 : training on 60244 raw words (36418 effective words) took 0.1s, 564196 effective words/s\n",
      "2021-01-21 22:54:52,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,326 : INFO : EPOCH - 29 : training on 60244 raw words (36447 effective words) took 0.1s, 549697 effective words/s\n",
      "2021-01-21 22:54:52,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,389 : INFO : EPOCH - 30 : training on 60244 raw words (36512 effective words) took 0.1s, 596816 effective words/s\n",
      "2021-01-21 22:54:52,442 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,447 : INFO : EPOCH - 31 : training on 60244 raw words (36355 effective words) took 0.1s, 657951 effective words/s\n",
      "2021-01-21 22:54:52,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,507 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,508 : INFO : EPOCH - 32 : training on 60244 raw words (36539 effective words) took 0.1s, 622124 effective words/s\n",
      "2021-01-21 22:54:52,556 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,566 : INFO : EPOCH - 33 : training on 60244 raw words (36350 effective words) took 0.0s, 735252 effective words/s\n",
      "2021-01-21 22:54:52,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,629 : INFO : EPOCH - 34 : training on 60244 raw words (36536 effective words) took 0.1s, 595353 effective words/s\n",
      "2021-01-21 22:54:52,685 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,691 : INFO : EPOCH - 35 : training on 60244 raw words (36338 effective words) took 0.1s, 612027 effective words/s\n",
      "2021-01-21 22:54:52,748 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,764 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,765 : INFO : EPOCH - 36 : training on 60244 raw words (36446 effective words) took 0.1s, 505558 effective words/s\n",
      "2021-01-21 22:54:52,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,844 : INFO : EPOCH - 37 : training on 60244 raw words (36477 effective words) took 0.1s, 481850 effective words/s\n",
      "2021-01-21 22:54:52,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:52,903 : INFO : EPOCH - 38 : training on 60244 raw words (36394 effective words) took 0.1s, 645071 effective words/s\n",
      "2021-01-21 22:54:52,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:52,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:52,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:52,977 : INFO : EPOCH - 39 : training on 60244 raw words (36552 effective words) took 0.1s, 504420 effective words/s\n",
      "2021-01-21 22:54:53,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,047 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,051 : INFO : EPOCH - 40 : training on 60244 raw words (36411 effective words) took 0.1s, 513767 effective words/s\n",
      "2021-01-21 22:54:53,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,127 : INFO : EPOCH - 41 : training on 60244 raw words (36556 effective words) took 0.1s, 492802 effective words/s\n",
      "2021-01-21 22:54:53,176 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,185 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,192 : INFO : EPOCH - 42 : training on 60244 raw words (36525 effective words) took 0.1s, 603406 effective words/s\n",
      "2021-01-21 22:54:53,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,271 : INFO : EPOCH - 43 : training on 60244 raw words (36509 effective words) took 0.1s, 467561 effective words/s\n",
      "2021-01-21 22:54:53,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,328 : INFO : EPOCH - 44 : training on 60244 raw words (36539 effective words) took 0.1s, 668203 effective words/s\n",
      "2021-01-21 22:54:53,382 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,394 : INFO : EPOCH - 45 : training on 60244 raw words (36469 effective words) took 0.1s, 568977 effective words/s\n",
      "2021-01-21 22:54:53,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,456 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,457 : INFO : EPOCH - 46 : training on 60244 raw words (36529 effective words) took 0.1s, 607802 effective words/s\n",
      "2021-01-21 22:54:53,510 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,517 : INFO : EPOCH - 47 : training on 60244 raw words (36399 effective words) took 0.1s, 640989 effective words/s\n",
      "2021-01-21 22:54:53,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,580 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,581 : INFO : EPOCH - 48 : training on 60244 raw words (36550 effective words) took 0.1s, 591609 effective words/s\n",
      "2021-01-21 22:54:53,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,650 : INFO : EPOCH - 49 : training on 60244 raw words (36528 effective words) took 0.1s, 542482 effective words/s\n",
      "2021-01-21 22:54:53,700 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,710 : INFO : EPOCH - 50 : training on 60244 raw words (36454 effective words) took 0.1s, 625424 effective words/s\n",
      "2021-01-21 22:54:53,761 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,768 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,772 : INFO : EPOCH - 51 : training on 60244 raw words (36542 effective words) took 0.1s, 611715 effective words/s\n",
      "2021-01-21 22:54:53,826 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,836 : INFO : EPOCH - 52 : training on 60244 raw words (36427 effective words) took 0.1s, 585419 effective words/s\n",
      "2021-01-21 22:54:53,895 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,901 : INFO : EPOCH - 53 : training on 60244 raw words (36574 effective words) took 0.1s, 570568 effective words/s\n",
      "2021-01-21 22:54:53,952 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:53,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:53,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:53,960 : INFO : EPOCH - 54 : training on 60244 raw words (36543 effective words) took 0.1s, 641972 effective words/s\n",
      "2021-01-21 22:54:54,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,014 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,028 : INFO : EPOCH - 55 : training on 60244 raw words (36497 effective words) took 0.1s, 548614 effective words/s\n",
      "2021-01-21 22:54:54,083 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,091 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,091 : INFO : EPOCH - 56 : training on 60244 raw words (36491 effective words) took 0.1s, 600959 effective words/s\n",
      "2021-01-21 22:54:54,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,159 : INFO : EPOCH - 57 : training on 60244 raw words (36446 effective words) took 0.1s, 550038 effective words/s\n",
      "2021-01-21 22:54:54,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,217 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,218 : INFO : EPOCH - 58 : training on 60244 raw words (36402 effective words) took 0.1s, 664214 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:54,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,280 : INFO : EPOCH - 59 : training on 60244 raw words (36459 effective words) took 0.1s, 601171 effective words/s\n",
      "2021-01-21 22:54:54,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,339 : INFO : EPOCH - 60 : training on 60244 raw words (36453 effective words) took 0.1s, 657830 effective words/s\n",
      "2021-01-21 22:54:54,393 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,405 : INFO : EPOCH - 61 : training on 60244 raw words (36488 effective words) took 0.1s, 558771 effective words/s\n",
      "2021-01-21 22:54:54,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,468 : INFO : EPOCH - 62 : training on 60244 raw words (36460 effective words) took 0.1s, 602299 effective words/s\n",
      "2021-01-21 22:54:54,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,533 : INFO : EPOCH - 63 : training on 60244 raw words (36491 effective words) took 0.1s, 575290 effective words/s\n",
      "2021-01-21 22:54:54,585 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,599 : INFO : EPOCH - 64 : training on 60244 raw words (36402 effective words) took 0.1s, 566245 effective words/s\n",
      "2021-01-21 22:54:54,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,652 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,653 : INFO : EPOCH - 65 : training on 60244 raw words (36504 effective words) took 0.1s, 714676 effective words/s\n",
      "2021-01-21 22:54:54,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,710 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,712 : INFO : EPOCH - 66 : training on 60244 raw words (36556 effective words) took 0.1s, 639128 effective words/s\n",
      "2021-01-21 22:54:54,758 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,766 : INFO : EPOCH - 67 : training on 60244 raw words (36423 effective words) took 0.1s, 689223 effective words/s\n",
      "2021-01-21 22:54:54,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,827 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,831 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,832 : INFO : EPOCH - 68 : training on 60244 raw words (36544 effective words) took 0.1s, 576114 effective words/s\n",
      "2021-01-21 22:54:54,886 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,893 : INFO : EPOCH - 69 : training on 60244 raw words (36577 effective words) took 0.1s, 622150 effective words/s\n",
      "2021-01-21 22:54:54,947 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:54,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:54,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:54,955 : INFO : EPOCH - 70 : training on 60244 raw words (36432 effective words) took 0.1s, 608406 effective words/s\n",
      "2021-01-21 22:54:55,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,007 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,010 : INFO : EPOCH - 71 : training on 60244 raw words (36404 effective words) took 0.1s, 697441 effective words/s\n",
      "2021-01-21 22:54:55,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,084 : INFO : EPOCH - 72 : training on 60244 raw words (36542 effective words) took 0.1s, 502384 effective words/s\n",
      "2021-01-21 22:54:55,133 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,143 : INFO : EPOCH - 73 : training on 60244 raw words (36534 effective words) took 0.1s, 650287 effective words/s\n",
      "2021-01-21 22:54:55,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,209 : INFO : EPOCH - 74 : training on 60244 raw words (36445 effective words) took 0.1s, 576351 effective words/s\n",
      "2021-01-21 22:54:55,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,282 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,283 : INFO : EPOCH - 75 : training on 60244 raw words (36536 effective words) took 0.1s, 512245 effective words/s\n",
      "2021-01-21 22:54:55,335 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,347 : INFO : EPOCH - 76 : training on 60244 raw words (36485 effective words) took 0.1s, 579122 effective words/s\n",
      "2021-01-21 22:54:55,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,410 : INFO : EPOCH - 77 : training on 60244 raw words (36433 effective words) took 0.1s, 610888 effective words/s\n",
      "2021-01-21 22:54:55,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,471 : INFO : EPOCH - 78 : training on 60244 raw words (36437 effective words) took 0.1s, 617683 effective words/s\n",
      "2021-01-21 22:54:55,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:55,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,529 : INFO : EPOCH - 79 : training on 60244 raw words (36453 effective words) took 0.1s, 645544 effective words/s\n",
      "2021-01-21 22:54:55,582 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,596 : INFO : EPOCH - 80 : training on 60244 raw words (36564 effective words) took 0.1s, 563493 effective words/s\n",
      "2021-01-21 22:54:55,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,663 : INFO : EPOCH - 81 : training on 60244 raw words (36494 effective words) took 0.1s, 566105 effective words/s\n",
      "2021-01-21 22:54:55,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,733 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,734 : INFO : EPOCH - 82 : training on 60244 raw words (36490 effective words) took 0.1s, 536616 effective words/s\n",
      "2021-01-21 22:54:55,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,800 : INFO : EPOCH - 83 : training on 60244 raw words (36382 effective words) took 0.1s, 560682 effective words/s\n",
      "2021-01-21 22:54:55,854 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,863 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,866 : INFO : EPOCH - 84 : training on 60244 raw words (36477 effective words) took 0.1s, 576160 effective words/s\n",
      "2021-01-21 22:54:55,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,925 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,930 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,931 : INFO : EPOCH - 85 : training on 60244 raw words (36538 effective words) took 0.1s, 582929 effective words/s\n",
      "2021-01-21 22:54:55,979 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:55,981 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:55,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:55,985 : INFO : EPOCH - 86 : training on 60244 raw words (36599 effective words) took 0.1s, 702464 effective words/s\n",
      "2021-01-21 22:54:56,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,045 : INFO : EPOCH - 87 : training on 60244 raw words (36436 effective words) took 0.1s, 626606 effective words/s\n",
      "2021-01-21 22:54:56,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,099 : INFO : EPOCH - 88 : training on 60244 raw words (36489 effective words) took 0.1s, 690966 effective words/s\n",
      "2021-01-21 22:54:56,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,167 : INFO : EPOCH - 89 : training on 60244 raw words (36424 effective words) took 0.1s, 563386 effective words/s\n",
      "2021-01-21 22:54:56,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,223 : INFO : EPOCH - 90 : training on 60244 raw words (36446 effective words) took 0.1s, 679860 effective words/s\n",
      "2021-01-21 22:54:56,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,293 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,294 : INFO : EPOCH - 91 : training on 60244 raw words (36435 effective words) took 0.1s, 537888 effective words/s\n",
      "2021-01-21 22:54:56,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,349 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,350 : INFO : EPOCH - 92 : training on 60244 raw words (36515 effective words) took 0.1s, 664533 effective words/s\n",
      "2021-01-21 22:54:56,407 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,422 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,422 : INFO : EPOCH - 93 : training on 60244 raw words (36401 effective words) took 0.1s, 522178 effective words/s\n",
      "2021-01-21 22:54:56,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,481 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,483 : INFO : EPOCH - 94 : training on 60244 raw words (36430 effective words) took 0.1s, 620414 effective words/s\n",
      "2021-01-21 22:54:56,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,533 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,537 : INFO : EPOCH - 95 : training on 60244 raw words (36645 effective words) took 0.1s, 698497 effective words/s\n",
      "2021-01-21 22:54:56,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,596 : INFO : EPOCH - 96 : training on 60244 raw words (36355 effective words) took 0.1s, 638026 effective words/s\n",
      "2021-01-21 22:54:56,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,659 : INFO : EPOCH - 97 : training on 60244 raw words (36433 effective words) took 0.1s, 604646 effective words/s\n",
      "2021-01-21 22:54:56,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,722 : INFO : EPOCH - 98 : training on 60244 raw words (36334 effective words) took 0.1s, 592131 effective words/s\n",
      "2021-01-21 22:54:56,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:54:56,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,777 : INFO : EPOCH - 99 : training on 60244 raw words (36522 effective words) took 0.1s, 680396 effective words/s\n",
      "2021-01-21 22:54:56,831 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-21 22:54:56,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-21 22:54:56,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-21 22:54:56,838 : INFO : EPOCH - 100 : training on 60244 raw words (36433 effective words) took 0.1s, 625833 effective words/s\n",
      "2021-01-21 22:54:56,839 : INFO : training on a 6024400 raw words (3647476 effective words) took 6.4s, 570522 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=1792, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, iter=100, min_count=5, size=200)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6: Odkomentuj poniższe linie i zobacz jak można wykorzystać uzyskany model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:55:25,106 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('stage', 0.48149171471595764)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['human', 'crime'], negative=['party'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:55:29,745 : WARNING : vectors for words {'input', 'cat', 'lunch'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"input is lunch he sentence cat\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.033215463\n",
      "0.2479491\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('human', 'tree'))\n",
    "print(model.wv.similarity('crime', 'murder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwagi dodatkowe:**\n",
    "+ uczenie modelu można zrównoleglić, ale trzeba doinstalować [Cythona](http://cython.org/)\n",
    "+ wytrenowany model można łatwo zapisać do pliku za pomocą: `model.save(path)`\n",
    "+ równie łatwo można go później wczytać: `model = gensim.models.Word2Vec.load(path)`\n",
    "+ ponieważ uczenie jest przyrostowe, można łatwo rozszerzyć istniejący słownik i douczyć model na nowych zdaniach:\n",
    "```\n",
    "model = gensim.models.Word2Vec.load(path)\n",
    "more_sentences = [['Advanced', 'users', 'can', 'load', 'a', 'model', 'and', 'continue', \n",
    "                  'training', 'it', 'with', 'more', 'sentences']]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystanie gotowego modelu do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Póki co sami trenowaliśmy word2vec i to na niedużych zbiorach danych. Na szczęście są już gotowe modele (przynajmniej dla języka angielskiego) nauczone na miliardach dokumentów i zawierające miliony słów. Przydatna lista takich modeli (wraz z kodem tworzącym usługę sieciową wykorzystującą model...) pod adresem: https://github.com/3Top/word2vec-api.\n",
    "\n",
    "**Zad. 7: Pobierz korpus Google News i zapisz pobrany plik do folderu data. Następnie wykonaj poniższy kod. Ta operacja zajmie jakieś 3-4 minuty i zużyje ok. 4 GB RAMU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:14:25,302 : INFO : loading projection weights from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2021-01-21 23:15:08,970 : INFO : loaded (3000000, 300) matrix from data/GoogleNews-vectors-negative300.bin.gz\n",
      "2021-01-21 23:15:08,972 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 4.05 s, total: 48.2 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 8: Zobacz jak działa model nauczony na tak dużym korpusie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192315101624)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664013\n",
      "0.32413524\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity('woman', 'man'))\n",
    "print(wv.similarity('woman', 'cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, super. Mam świetny model, mogę nim podpowiadać słowa, wynajdować niepasujące elementy, uzupełniać zdania, znajdować synonimy, itd. Ale czy da się to jakoś wykorzystać do klasyfikacji? word2vec ma wektor na każde słowo - jak z tego zrobić wektor na ciąg słów?\n",
    "\n",
    "**Odpowiedź: można uśrednić znaczenie słów w dokuemncie poprzez zsumowanie wektorów wszystkich słów.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo szybko spróbujemy zastosować to podejście do predykcji gatunku filmu na podstawie jego opisu. Poniżej kod wczytujący ciekawy zbiór danych oraz pokazujący jakie ma klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 23:22:52,260 : INFO : Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-01-21 23:22:52,261 : INFO : NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  movieId                                               plot  \\\n",
      "0           0        1  A little boy named Andy loves to be in his roo...   \n",
      "1           1        2  When two kids find and play a magical board ga...   \n",
      "2           2        3  Things don't seem to change much in Wabasha Co...   \n",
      "3           3        6  Hunters and their prey--Neil and his professio...   \n",
      "4           4        7  An ugly duckling having undergone a remarkable...   \n",
      "\n",
      "         tag  \n",
      "0  animation  \n",
      "1    fantasy  \n",
      "2     comedy  \n",
      "3     action  \n",
      "4    romance  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fed31317130>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('data/tagged_plots_movielens.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "df.tag.value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szybko dzielimy dane na zbiór uczący i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizujemy dane i wyliczamy reprezentację wektorową (za pomocą zsumowanych wektorów słów wrod2vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczymy i testujemy klasyfikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, train_data['tag'])\n",
    "predicted = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrzymy jak nam poszło:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafność klasyfikacji 0.5390946502057613\n",
      "Macierz pomyłek\n",
      " [[23  2 10  0  1  6]\n",
      " [ 3 10  8  3  4  3]\n",
      " [ 2  5 55  2 18  4]\n",
      " [ 3  4  4  4  0  1]\n",
      " [ 4  0 12  1 16  2]\n",
      " [ 5  0  3  0  2 23]]\n"
     ]
    }
   ],
   "source": [
    "print('Trafność klasyfikacji %s' % accuracy_score(test_data.tag, predicted))\n",
    "cm = confusion_matrix(test_data.tag, predicted)\n",
    "print('Macierz pomyłek\\n %s' % cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak na brak porządnego przetwarzania wstępnego, nie jest to zły wynik. Mam nadzieję, że ten przykład pokazał jak można wykorzystać word2vec do tworzenia atrybutów dla problemów klasyfikacyjnych."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
