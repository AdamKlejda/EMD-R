{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selekcja i ekstrakcja cech za pomocą scikit-learn\n",
    "\n",
    "Ten notatnik pomoże Ci zapoznać się z metodami przetwarzania wstępnego danych w Pythonie. Po uzupełnieniu tego notatnika powinieneś:\n",
    "\n",
    "+ zapoznać się klasą Pipeline,\n",
    "+ wiedzieć jak znormalizować dane,\n",
    "+ umieć uruchomić algorytm selekcji cech,\n",
    "+ wiedzieć jak wykonać analizę PCA\n",
    "\n",
    "Wszystkie algorytmy będziemy uruchamiać na jednym zbiorze danych: [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Podczas przetwarzania wstępnego danych należy uważać, żeby nie korzystać z danych testowych. Wszakże jeśli nasz model zostanie uruchomiany na danych produkcyjnych będą to zupełnie nowe danych i nie będziemy zbyt dużo o nich wiedzieć w trakcie dokonywania predykcji.\n",
    "\n",
    "Aby ułatwić użytkownikom biblioteki `scikit-learn` przetwarzanie wstępne z możliwością rozróżnienia danych treningowych od testowych, wprowadzono klasę `Pipeline`. Klasa `Pipeline` definiuje sekwencje kroków (transformacji), które należy wykonać na danych. Kolejnymi krokami pipeline'a mogą być:\n",
    "\n",
    "- inżynieria nowych cech\n",
    "- normalizacja danych\n",
    "- usuwanie outlierów\n",
    "- selekcja cech\n",
    "- ekstrakcja cech\n",
    "- uczenie klasyfikatora\n",
    "\n",
    "Typowe pipeline'y są z reguły znacznie krótsze ;) Przydatna dokumentacja jak zwykle na stronie scikit-learn: [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "**Zad. 1: Załaduj wskazany zbiór danych i stwórz swój pierwszy pipeline. Pipeline powinien mieć dwa kroki: normalizację danych i uczenie regresora.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.7007\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 23\n",
    "\n",
    "# 0. Zbiór danych\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)\n",
    "\n",
    "# 1. stwórz obiekt do normalizacji danych\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 2. stwórz klasyfikator\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "# 3. stwórz Pipeline z dwoma krokami, kroki nazwij \"scaler\" i \"clf\" i niech zawierają obiekty scaler i clf\n",
    "pipe = Pipeline([(\"scaler\",scaler),(\"clf\",clf)])\n",
    "\n",
    "# 4. Odpal pipeline\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` działa trochę jak klasyfikator połączony ze wstępnym przetwarzaniem. Można zatem podać stworzony przez siebie obiekt typu `Pipeline` jako parametr `GirdSearchCV`. Ale zanim do tego przejdziemy skupmy się na metodach selekcji cech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja cech\n",
    "\n",
    "W poniższych sekcjach szybko spojrzymy na implementacje różnych metod selekcji cech w bibliotece `scikit-learn`. Warto zaznaczyć, że selekcja cech to bardzo szeroka działka naukowa i algorytmów jest multum. Stosunkowo niedawno pojawiła się biblioteka [`scikit-feature`](http://featureselection.asu.edu/), która rozszerza zbiór algorytmów dostępnych w `scikit-learn`. [`scikit-feature`](http://featureselection.asu.edu/) nie jest biblioteką, która jest oficjalnie wspierana przez ludzi tworzących `scikit-learn`, ale może to być dobre miejsce do poszukiwań implementacji mniej popularnych algorytmów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody filter\n",
    "\n",
    "Zacznijmy od zbadania wariancji. Do tego przyda Ci się klasa [`Variancethreshold`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html). Jeśli wariancja jest zero (kolumna ma tylko jedną wartość) na pewno warto sprawdzić czy to nie jakiś błąd. Jeśli dana kolumna to po prostu stała, można ją z czystym sumieniem usunać. Mając rozeznanie w danych, można również ustawić minimalny próg zmienności.\n",
    "\n",
    "**Zad. 2: Sprawdź czy w zbiorze danych są atrybuty o zmienności mniejszej niż 0.05.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATRYBUTY: ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "LICZBA 13\n",
      "(379, 13)\n",
      "(379, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 1. Sprawdź ile atrybutów ma zbiór danych\n",
    "print(\"ATRYBUTY:\",names)\n",
    "print(\"LICZBA\",len(names))\n",
    "# 2. Użyj metody fit_transform na obiekcie klasy VarianceThreshold\n",
    "var_T = VarianceThreshold(threshold = 0.5)\n",
    "X_trans =  var_T.fit_transform(X_train)\n",
    "# 3. Sprawdź ile atrybutów ma przetransformowany zbiór danych\n",
    "print(X_train.shape)\n",
    "print(X_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inną prostą metodą jest badanie korelacji między zmiennymi a wartością przewidywaną. W `scikit-learn` służą do tego metody `chi2`, `f_classif` i `f_regression`. Ponieważ przewidujemy wartość ciągłą, sprawdźmy działanie tej ostatniej. Uwaga! Metody te oceniają każdą cechę osobno, dlatego cechy skorelowane będą podobnie ocenione.\n",
    "\n",
    "**Zad. 3: Oceń atrybuty na podstawie ich korelacji z atrybutem decyzyjnym.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: 78.50 (p=0.000)\n",
      "ZN: 63.28 (p=0.000)\n",
      "INDUS: 106.05 (p=0.000)\n",
      "CHAS: 12.59 (p=0.000)\n",
      "NOX: 86.93 (p=0.000)\n",
      "RM: 366.32 (p=0.000)\n",
      "AGE: 72.51 (p=0.000)\n",
      "DIS: 29.16 (p=0.000)\n",
      "RAD: 67.46 (p=0.000)\n",
      "TAX: 106.88 (p=0.000)\n",
      "PTRATIO: 132.46 (p=0.000)\n",
      "B: 55.38 (p=0.000)\n",
      "LSTAT: 473.74 (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# 1. Odpalf_regression, aby uzyskać ocenę korelacji\n",
    "f_scores, p_values = f_regression(X_train,y_train)\n",
    "\n",
    "# 2. Wypisz wynik dla każdego atrybutu\n",
    "for i in range(len(names)):\n",
    "    print('{0}: {1:.2f} (p={2:.3f})'.format(names[i], f_scores[i], p_values[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znając korelację bądź inną wartość oceniającą atrybuty, możemy wybrać podzbioru najlepszych atrybutów. Do tego służą klasy `SelectKBest` i `SelectPercentile`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass k=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# 1. Stwórz obiekt SelectKBest z odpowiednimi parametrami\n",
    "selector = SelectKBest(f_regression,5)\n",
    "# 2. Stwórz pipeline z krokami scaler, selector i clf\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"selector\", selector), (\"clf\", clf)])\n",
    "# 3. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Powtórz poprzednie zadanie wykorzystując tym razem miarę `mutual_info_regression`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass k=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.2747\n"
     ]
    }
   ],
   "source": [
    "# 1. Stwórz obiekt SelectKBest z odpowiednimi parametrami\n",
    "selector = SelectKBest(mutual_info_regression,5)\n",
    "\n",
    "# 2. Stwórz pipeline z krokami scaler, selector i clf\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"selector\", selector), (\"clf\", clf)])\n",
    "\n",
    "# 3. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody wrapper\n",
    "\n",
    "Klasyczne metody typu wrapper nie są dostępne jako funkcje w `scikit-learn`. Można samemu zaimplementować brute-force, forward selction bądź backward selection lub... posiłkować się biblioteką [`mlxtend`](http://rasbt.github.io/mlxtend/) i zawartymi tam klasami `ExhaustiveFeatureSelector` (brute-force) i `SequentialFeatureSelector` (backward/foward selection). Biblioteka `mlxtend` zawiera wiele innych bardzo ciekawych rozszerzeń do `scikit-learn` (np. Stacking czy EnsembleVote) więc warto pamiętać o tej bibliotece.\n",
    "\n",
    "Zamiast rozwodzić się nad klasycznymi metodami typu wrapper, które są bardzo kosztowne obliczeniowo, wypróbujmy algorytm RFE. Dla przypomnienia, algorytm RFE ocenia atrybuty a następnie usuwa najsłabszy z nich. Czynność ta jest powtarzana aż uzyskamy oczekiwaną liczbę atrybutów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6: Skorzystaj z klasy [`RFECV`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) aby znaleźć najlepszy podzbiór atrybutów. Użyj 10-krotnej oceny krzyżowej.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: 1\n",
      "ZN: 4\n",
      "INDUS: 2\n",
      "CHAS: 5\n",
      "NOX: 1\n",
      "RM: 1\n",
      "AGE: 1\n",
      "DIS: 1\n",
      "RAD: 3\n",
      "TAX: 1\n",
      "PTRATIO: 1\n",
      "B: 1\n",
      "LSTAT: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# 1. Odpal RFECV na danych treningowych\n",
    "selector = RFECV(clf, cv=10)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "# 2. Wypisz ranking atrybutów\n",
    "for i in range(len(names)):\n",
    "    print('{0}: {1}'.format(names[i], selector.ranking_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo fajną hybrydą jest również algorytm Stability Selection. Jest to algorytm dość kosztowny ale łączy elementy interpretacji atrybutów oraz poprawiania trafności predykcji. Zainteresowani mogą zajrzeć do klas [`RandomizedLogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLogisticRegression.html) (klasyfikacja) i [`RandomizedLasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso) (regresja) w dokumentacji `scikit-learn`. Obie klasy są obecnie DEPRACATED, ale liczę że po prostu przeniosą je do modułu `feature_selection`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody embedded\n",
    "\n",
    "Modele liniowe są od lat stosowane do określania ważności atrybutów. Modele liniowe bez regularyzacji potrafią wskazać ważność atrybutów jeśli dane nie są zbyt mocono zaszumione i atrybuty nie są ze sobą skorelowane.\n",
    "\n",
    "Modele liniowe z regularyzacją radzą sobie lepiej z szumem i korelacją. Regularyzacja L1 (LASSO) usuwa atrybuty i może być stosowana do selekcji cech w celu poprawy trafności predykcji. Regularyzacja L2 (Ridge regression) jest bardzie stabilna, nie usuwa atrybutów i może być stosowania do oceny atrybutów w celach interpretacyjnych.\n",
    "\n",
    "**Zad. 7: Naucz modele liniowe i sprawdź wagi przypisane kolejnym atrybutom by ocenić ich ważność. Nie zapomnij  oznormalizowaniu danych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model:  -3.797 * LSTAT + 3.003 * RM + -1.541 * PTRATIO + -1.024 * DIS + 0.883 * B + 0.746 * CHAS + -0.557 * NOX + 0.2 * ZN + -0.061 * CRIM + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n",
      "------------------------------------------------------------------------------------\n",
      "Ridge model:  -3.794 * LSTAT + -3.047 * DIS + 2.772 * RM + 2.389 * RAD + -2.159 * NOX + -1.88 * PTRATIO + -1.555 * TAX + 1.149 * B + 1.109 * ZN + 0.864 * CHAS + -0.797 * CRIM + 0.167 * INDUS + 0.055 * AGE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names is None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "# 1. Odpal Lasso z alpha=0.3 w pipeline'ie z normalizacją\n",
    "lasso = Lasso(alpha=0.3)\n",
    "lasso_pipe = Pipeline([(\"scaler\", scaler), (\"lasso\", lasso)])\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2. Odpal Ridge z alpha=0.3 w pipeline'ie z normalizacją\n",
    "ridge = Ridge(alpha=0.3)\n",
    "ridge_pipe = Pipeline([(\"scaler\", scaler), (\"ridge\", ridge)])\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "# 3. Wypisz uzyskane modele\n",
    "print(\"Lasso model: \", pretty_print_linear(lasso_pipe.steps[1][1].coef_, names, sort = True))\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print(\"Ridge model: \", pretty_print_linear(ridge_pipe.steps[1][1].coef_, names, sort = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstrakcja cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec zobaczymy jak w Pythonie policzyć PCA i na tej podstawie zmniejszyć liczbę atrybutów. Uwaga! Trzeba znormalizować dane przed analizą PCA, aby nie przecenić atrybutów o większym zakresie wartości i wten sposób nie wykonać gorszej transformacji.\n",
    "\n",
    "**Zad. 8: Wykonaj analizę PCA zgodnie z poniższymi krokami.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.5057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. Znormalizuj dane, odpal PCA i zobacz ile atrybutów potrzeba do wyjaśnienia zmienności w danych\n",
    "pca = Pipeline([('scaler', scaler), ('extractor', PCA())])\n",
    "pca.fit(X_train)\n",
    "\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "plt.plot(pca.steps[1][1].explained_variance_, linewidth=2)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance')\n",
    "\n",
    "\n",
    "# 2. Stwórz nowy obiekt PCA i ogranicz liczbę cech do określonej na podstawie wykresu liczby\n",
    "pca = PCA(n_components=6)\n",
    "# 3. Stwórz pipeline z krokami scaler, extractor i clf\n",
    "pipe = Pipeline([('scaler', scaler), ('extractor', pca), (\"clf\", clf)])\n",
    "# 4. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie bonusowe\n",
    "\n",
    "**Zad. 9*: Zaimplementuj grid search, który wypróbuje wiele metod selekcji cech (potencjalnie z różnymi parametrami) i wybierze najlepsze wstępne przetwarzanie danych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'mae', 'clf__n_estimators': 100, 'extractor__n_components': 9, 'scaler': RobustScaler(), 'selector': 'passthrough'}\n",
      "RMSE: 4.1354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pipe =  Pipeline([\n",
    "    (\"scaler\", None),\n",
    "    (\"extractor\", PCA()),\n",
    "    (\"selector\", None),\n",
    "    (\"clf\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "tuned_parameters = [{\n",
    "    \"scaler\": [preprocessing.StandardScaler(), preprocessing.Normalizer(), preprocessing.RobustScaler()],\n",
    "    \"extractor__n_components\": [3,5,9],\n",
    "    \"selector\": ['passthrough',Lasso(), Ridge()],\n",
    "    \"clf__n_estimators\": [10,100],\n",
    "    \"clf__criterion\": [\"mse\", \"mae\"],\n",
    "}]\n",
    "\n",
    "clf = GridSearchCV(pipe,\n",
    "                  tuned_parameters,\n",
    "                  cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
